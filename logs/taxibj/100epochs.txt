DATCSTP(
  (pe): PatchEmbed_CNN3D(
    (net): Sequential(
      (0): Conv3d(2, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
      (1): GELU(approximate='none')
      (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (4): GELU(approximate='none')
      (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    )
  )
  (net): ModuleList(
    (0-5): 6 x Block(
      (drop_path): Identity()
      (satt): Attention(
        (norm): LayerNorm()
        (att): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        )
        (v): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        (proj): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      )
      (tatt): Attention(
        (norm): LayerNorm()
        (att): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        )
        (v): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        (proj): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      )
      (mlp): Mlp(
        (norm): LayerNorm()
        (fc1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
        (pos): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        (fc2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        (act): GELU(approximate='none')
      )
    )
  )
  (pb): PatchEmbed_CNN3D(
    (net): Sequential(
      (0): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
      (1): GELU(approximate='none')
      (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (4): GELU(approximate='none')
      (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ConvTranspose3d(64, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)
    )
  )
)
| module             | #parameters or shape   | #flops    |
|:-------------------|:-----------------------|:----------|
| model              | 1.449M                 | 0.194G    |
|  pe.net            |  0.18M                 |  62.915M  |
|   pe.net.0         |   3.456K               |   1.769M  |
|    pe.net.0.weight |    (64, 2, 3, 3, 3)    |           |
|   pe.net.2         |   0.128K               |   0.164M  |
|    pe.net.2.weight |    (64,)               |           |
|    pe.net.2.bias   |    (64,)               |           |
|   pe.net.3         |   0.111M               |   56.623M |
|    pe.net.3.weight |    (64, 64, 3, 3, 3)   |           |
|   pe.net.5         |   0.128K               |   0.164M  |
|    pe.net.5.weight |    (64,)               |           |
|    pe.net.5.bias   |    (64,)               |           |
|   pe.net.6         |   65.536K              |   4.194M  |
|    pe.net.6.weight |    (128, 64, 2, 2, 2)  |           |
|  net               |  1.089M                |  68.616M  |
|   net.0            |   0.182M               |   11.436M |
|    net.0.scale1    |    (128,)              |           |
|    net.0.scale2    |    (128,)              |           |
|    net.0.scale3    |    (128,)              |           |
|    net.0.satt      |    56.192K             |    3.547M |
|    net.0.tatt      |    56.192K             |    3.547M |
|    net.0.mlp       |    68.736K             |    4.342M |
|   net.1            |   0.182M               |   11.436M |
|    net.1.scale1    |    (128,)              |           |
|    net.1.scale2    |    (128,)              |           |
|    net.1.scale3    |    (128,)              |           |
|    net.1.satt      |    56.192K             |    3.547M |
|    net.1.tatt      |    56.192K             |    3.547M |
|    net.1.mlp       |    68.736K             |    4.342M |
|   net.2            |   0.182M               |   11.436M |
|    net.2.scale1    |    (128,)              |           |
|    net.2.scale2    |    (128,)              |           |
|    net.2.scale3    |    (128,)              |           |
|    net.2.satt      |    56.192K             |    3.547M |
|    net.2.tatt      |    56.192K             |    3.547M |
|    net.2.mlp       |    68.736K             |    4.342M |
|   net.3            |   0.182M               |   11.436M |
|    net.3.scale1    |    (128,)              |           |
|    net.3.scale2    |    (128,)              |           |
|    net.3.scale3    |    (128,)              |           |
|    net.3.satt      |    56.192K             |    3.547M |
|    net.3.tatt      |    56.192K             |    3.547M |
|    net.3.mlp       |    68.736K             |    4.342M |
|   net.4            |   0.182M               |   11.436M |
|    net.4.scale1    |    (128,)              |           |
|    net.4.scale2    |    (128,)              |           |
|    net.4.scale3    |    (128,)              |           |
|    net.4.satt      |    56.192K             |    3.547M |
|    net.4.tatt      |    56.192K             |    3.547M |
|    net.4.mlp       |    68.736K             |    4.342M |
|   net.5            |   0.182M               |   11.436M |
|    net.5.scale1    |    (128,)              |           |
|    net.5.scale2    |    (128,)              |           |
|    net.5.scale3    |    (128,)              |           |
|    net.5.satt      |    56.192K             |    3.547M |
|    net.5.tatt      |    56.192K             |    3.547M |
|    net.5.mlp       |    68.736K             |    4.342M |
|  pb.net            |  0.18M                 |  62.915M  |
|   pb.net.0         |   65.536K              |   4.194M  |
|    pb.net.0.weight |    (128, 64, 2, 2, 2)  |           |
|   pb.net.2         |   0.128K               |   0.164M  |
|    pb.net.2.weight |    (64,)               |           |
|    pb.net.2.bias   |    (64,)               |           |
|   pb.net.3         |   0.111M               |   56.623M |
|    pb.net.3.weight |    (64, 64, 3, 3, 3)   |           |
|   pb.net.5         |   0.128K               |   0.164M  |
|    pb.net.5.weight |    (64,)               |           |
|    pb.net.5.bias   |    (64,)               |           |
|   pb.net.6         |   3.456K               |   1.769M  |
|    pb.net.6.weight |    (64, 2, 3, 3, 3)    |           |
model params: 1448704
model gflops: 0.194445312
Epoch 1 | Loss : 0.749536 | Time : 55.1404
Epoch 1 | Test Loss : 0.005508 | Time : 0.4284
Best model saved with loss 0.005508 at epoch 1
Epoch 2 | Loss : 0.103293 | Time : 54.8953
Epoch 2 | Test Loss : 0.002815 | Time : 0.3846
Best model saved with loss 0.002815 at epoch 2
Epoch 3 | Loss : 0.034350 | Time : 55.4959
Epoch 3 | Test Loss : 0.000554 | Time : 0.3856
Best model saved with loss 0.000554 at epoch 3
Epoch 4 | Loss : 0.024081 | Time : 55.4633
Epoch 4 | Test Loss : 0.000444 | Time : 0.3891
Best model saved with loss 0.000444 at epoch 4
Epoch 5 | Loss : 0.021397 | Time : 55.2400
Epoch 5 | Test Loss : 0.000399 | Time : 0.4313
Best model saved with loss 0.000399 at epoch 5
Epoch 6 | Loss : 0.019468 | Time : 54.8734
Epoch 6 | Test Loss : 0.000407 | Time : 0.3845
Epoch 7 | Loss : 0.018353 | Time : 54.9132
Epoch 7 | Test Loss : 0.000343 | Time : 0.4146
Best model saved with loss 0.000343 at epoch 7
Epoch 8 | Loss : 0.016245 | Time : 55.9668
Epoch 8 | Test Loss : 0.000311 | Time : 0.4067
Best model saved with loss 0.000311 at epoch 8
Epoch 9 | Loss : 0.015322 | Time : 55.4643
Epoch 9 | Test Loss : 0.000320 | Time : 0.4304
Epoch 10 | Loss : 0.014549 | Time : 54.7806
Epoch 10 | Test Loss : 0.000274 | Time : 0.4112
Best model saved with loss 0.000274 at epoch 10
Epoch 11 | Loss : 0.013885 | Time : 54.9414
Epoch 11 | Test Loss : 0.000287 | Time : 0.4166
Epoch 12 | Loss : 0.013501 | Time : 54.9244
Epoch 12 | Test Loss : 0.000271 | Time : 0.3877
Best model saved with loss 0.000271 at epoch 12
Epoch 13 | Loss : 0.013067 | Time : 56.3543
Epoch 13 | Test Loss : 0.000274 | Time : 0.3766
Epoch 14 | Loss : 0.012897 | Time : 55.1200
Epoch 14 | Test Loss : 0.000260 | Time : 0.3857
Best model saved with loss 0.000260 at epoch 14
Epoch 15 | Loss : 0.012683 | Time : 55.6191
Epoch 15 | Test Loss : 0.000249 | Time : 0.4130
Best model saved with loss 0.000249 at epoch 15
Epoch 16 | Loss : 0.012402 | Time : 55.9003
Epoch 16 | Test Loss : 0.000239 | Time : 0.3902
Best model saved with loss 0.000239 at epoch 16
Epoch 17 | Loss : 0.012134 | Time : 56.0345
Epoch 17 | Test Loss : 0.000217 | Time : 0.4188
Best model saved with loss 0.000217 at epoch 17
Epoch 18 | Loss : 0.011998 | Time : 54.9551
Epoch 18 | Test Loss : 0.000227 | Time : 0.3710
Epoch 19 | Loss : 0.011861 | Time : 54.2514
Epoch 19 | Test Loss : 0.000239 | Time : 0.3816
Epoch 20 | Loss : 0.011614 | Time : 55.3047
Epoch 20 | Test Loss : 0.000208 | Time : 0.3669
Best model saved with loss 0.000208 at epoch 20
Epoch 21 | Loss : 0.011492 | Time : 54.9290
Epoch 21 | Test Loss : 0.000210 | Time : 0.4410
Epoch 22 | Loss : 0.011442 | Time : 55.2092
Epoch 22 | Test Loss : 0.000200 | Time : 0.4015
Best model saved with loss 0.000200 at epoch 22
Epoch 23 | Loss : 0.011331 | Time : 54.6434
Epoch 23 | Test Loss : 0.000227 | Time : 0.3947
Epoch 24 | Loss : 0.011190 | Time : 56.2317
Epoch 24 | Test Loss : 0.000198 | Time : 0.4155
Best model saved with loss 0.000198 at epoch 24
Epoch 25 | Loss : 0.011130 | Time : 56.0981
Epoch 25 | Test Loss : 0.000183 | Time : 0.3934
Best model saved with loss 0.000183 at epoch 25
Epoch 26 | Loss : 0.010914 | Time : 55.2474
Epoch 26 | Test Loss : 0.000210 | Time : 0.4421
Epoch 27 | Loss : 0.010883 | Time : 54.3252
Epoch 27 | Test Loss : 0.000190 | Time : 0.3729
Epoch 28 | Loss : 0.010730 | Time : 54.4867
Epoch 28 | Test Loss : 0.000207 | Time : 0.3887
Epoch 29 | Loss : 0.010653 | Time : 55.9938
Epoch 29 | Test Loss : 0.000194 | Time : 0.4419
Epoch 30 | Loss : 0.010663 | Time : 56.2087
Epoch 30 | Test Loss : 0.000191 | Time : 0.3687
Epoch 31 | Loss : 0.010538 | Time : 55.4032
Epoch 31 | Test Loss : 0.000369 | Time : 0.4158
Epoch 32 | Loss : 0.010433 | Time : 54.8116
Epoch 32 | Test Loss : 0.000192 | Time : 0.3775
Epoch 33 | Loss : 0.010579 | Time : 55.5323
Epoch 33 | Test Loss : 0.000176 | Time : 0.4188
Best model saved with loss 0.000176 at epoch 33
Epoch 34 | Loss : 0.010288 | Time : 55.9043
Epoch 34 | Test Loss : 0.000182 | Time : 0.3812
Epoch 35 | Loss : 0.010225 | Time : 56.0055
Epoch 35 | Test Loss : 0.000177 | Time : 0.4056
Epoch 36 | Loss : 0.010064 | Time : 55.0864
Epoch 36 | Test Loss : 0.000195 | Time : 0.3686
Epoch 37 | Loss : 0.010045 | Time : 54.7911
Epoch 37 | Test Loss : 0.000185 | Time : 0.3677
Epoch 38 | Loss : 0.010145 | Time : 55.3312
Epoch 38 | Test Loss : 0.000176 | Time : 0.4006
Best model saved with loss 0.000176 at epoch 38
Epoch 39 | Loss : 0.009882 | Time : 54.7134
Epoch 39 | Test Loss : 0.000193 | Time : 0.4049
Epoch 40 | Loss : 0.009896 | Time : 55.4366
Epoch 40 | Test Loss : 0.000182 | Time : 0.3993
Epoch 41 | Loss : 0.009704 | Time : 55.3871
Epoch 41 | Test Loss : 0.000171 | Time : 0.4316
Best model saved with loss 0.000171 at epoch 41
Epoch 42 | Loss : 0.009824 | Time : 54.6973
Epoch 42 | Test Loss : 0.000175 | Time : 0.3864
Epoch 43 | Loss : 0.009659 | Time : 54.6949
Epoch 43 | Test Loss : 0.000176 | Time : 0.4120
Epoch 44 | Loss : 0.009573 | Time : 55.8437
Epoch 44 | Test Loss : 0.000189 | Time : 0.3651
Epoch 45 | Loss : 0.009647 | Time : 54.3600
Epoch 45 | Test Loss : 0.000242 | Time : 0.3798
Epoch 46 | Loss : 0.009576 | Time : 55.2347
Epoch 46 | Test Loss : 0.000182 | Time : 0.3840
Epoch 47 | Loss : 0.009455 | Time : 55.3503
Epoch 47 | Test Loss : 0.000159 | Time : 0.3717
Best model saved with loss 0.000159 at epoch 47
Epoch 48 | Loss : 0.009453 | Time : 55.7937
Epoch 48 | Test Loss : 0.000166 | Time : 0.4014
Epoch 49 | Loss : 0.009361 | Time : 55.3636
Epoch 49 | Test Loss : 0.000170 | Time : 0.3993
Epoch 50 | Loss : 0.009242 | Time : 54.6742
Epoch 50 | Test Loss : 0.000171 | Time : 0.4183
Epoch 51 | Loss : 0.009241 | Time : 54.6693
Epoch 51 | Test Loss : 0.000169 | Time : 0.3971
Epoch 52 | Loss : 0.009169 | Time : 55.8670
Epoch 52 | Test Loss : 0.000185 | Time : 0.4085
Epoch 53 | Loss : 0.009092 | Time : 55.3577
Epoch 53 | Test Loss : 0.000189 | Time : 0.4078
Epoch 54 | Loss : 0.009011 | Time : 55.2831
Epoch 54 | Test Loss : 0.000163 | Time : 0.4063
Epoch 55 | Loss : 0.009012 | Time : 54.9060
Epoch 55 | Test Loss : 0.000168 | Time : 0.3975
Epoch 56 | Loss : 0.008966 | Time : 55.0238
Epoch 56 | Test Loss : 0.000163 | Time : 0.4049
Epoch 57 | Loss : 0.008912 | Time : 54.5731
Epoch 57 | Test Loss : 0.000163 | Time : 0.4019
Epoch 58 | Loss : 0.008903 | Time : 55.5770
Epoch 58 | Test Loss : 0.000167 | Time : 0.4055
Epoch 59 | Loss : 0.008811 | Time : 54.6367
Epoch 59 | Test Loss : 0.000161 | Time : 0.3739
Epoch 60 | Loss : 0.008818 | Time : 55.2747
Epoch 60 | Test Loss : 0.000167 | Time : 0.3611
Epoch 61 | Loss : 0.008801 | Time : 55.1820
Epoch 61 | Test Loss : 0.000169 | Time : 0.4130
Epoch 62 | Loss : 0.008774 | Time : 55.4540
Epoch 62 | Test Loss : 0.000164 | Time : 0.3878
Epoch 63 | Loss : 0.008680 | Time : 54.1085
Epoch 63 | Test Loss : 0.000164 | Time : 0.3821
Epoch 64 | Loss : 0.008610 | Time : 54.8795
Epoch 64 | Test Loss : 0.000160 | Time : 0.4024
Epoch 65 | Loss : 0.008571 | Time : 55.6325
Epoch 65 | Test Loss : 0.000156 | Time : 0.3881
Best model saved with loss 0.000156 at epoch 65
Epoch 66 | Loss : 0.008605 | Time : 54.6152
Epoch 66 | Test Loss : 0.000166 | Time : 0.4080
Epoch 67 | Loss : 0.008518 | Time : 55.7028
Epoch 67 | Test Loss : 0.000153 | Time : 0.3968
Best model saved with loss 0.000153 at epoch 67
Epoch 68 | Loss : 0.008492 | Time : 55.1413
Epoch 68 | Test Loss : 0.000160 | Time : 0.3968
Epoch 69 | Loss : 0.008499 | Time : 54.6058
Epoch 69 | Test Loss : 0.000167 | Time : 0.4362
Epoch 70 | Loss : 0.008468 | Time : 54.9880
Epoch 70 | Test Loss : 0.000164 | Time : 0.3836
Epoch 71 | Loss : 0.008373 | Time : 55.1269
Epoch 71 | Test Loss : 0.000172 | Time : 0.4207
Epoch 72 | Loss : 0.008420 | Time : 56.0822
Epoch 72 | Test Loss : 0.000164 | Time : 0.4080
Epoch 73 | Loss : 0.008434 | Time : 57.5220
Epoch 73 | Test Loss : 0.000160 | Time : 0.3300
Epoch 74 | Loss : 0.008340 | Time : 58.2511
Epoch 74 | Test Loss : 0.000167 | Time : 0.3146
Epoch 75 | Loss : 0.008301 | Time : 60.6306
Epoch 75 | Test Loss : 0.000164 | Time : 0.3334
Epoch 76 | Loss : 0.008271 | Time : 60.0558
Epoch 76 | Test Loss : 0.000161 | Time : 0.3008
Epoch 77 | Loss : 0.008292 | Time : 60.7482
Epoch 77 | Test Loss : 0.000165 | Time : 0.3168
Epoch 78 | Loss : 0.008254 | Time : 59.1671
Epoch 78 | Test Loss : 0.000162 | Time : 0.3051
Epoch 79 | Loss : 0.008231 | Time : 58.2068
Epoch 79 | Test Loss : 0.000162 | Time : 0.3037
Epoch 80 | Loss : 0.008152 | Time : 60.4276
Epoch 80 | Test Loss : 0.000164 | Time : 0.2993
Epoch 81 | Loss : 0.008194 | Time : 60.0260
Epoch 81 | Test Loss : 0.000163 | Time : 0.2975
Epoch 82 | Loss : 0.008184 | Time : 59.8041
Epoch 82 | Test Loss : 0.000162 | Time : 0.3242
Epoch 83 | Loss : 0.008182 | Time : 60.1220
Epoch 83 | Test Loss : 0.000164 | Time : 0.2991
Epoch 84 | Loss : 0.008152 | Time : 59.8663
Epoch 84 | Test Loss : 0.000162 | Time : 0.2992
Epoch 85 | Loss : 0.008143 | Time : 60.0248
Epoch 85 | Test Loss : 0.000162 | Time : 0.3050
Epoch 86 | Loss : 0.008088 | Time : 60.2366
Epoch 86 | Test Loss : 0.000163 | Time : 0.3277
Epoch 87 | Loss : 0.008095 | Time : 59.9200
Epoch 87 | Test Loss : 0.000166 | Time : 0.3095
Epoch 88 | Loss : 0.008067 | Time : 60.2836
Epoch 88 | Test Loss : 0.000164 | Time : 0.2931
Epoch 89 | Loss : 0.008070 | Time : 59.6307
Epoch 89 | Test Loss : 0.000166 | Time : 0.2706
Epoch 90 | Loss : 0.008028 | Time : 59.4117
Epoch 90 | Test Loss : 0.000165 | Time : 0.3002
Epoch 91 | Loss : 0.008074 | Time : 58.6980
Epoch 91 | Test Loss : 0.000163 | Time : 0.3021
Epoch 92 | Loss : 0.008066 | Time : 60.4041
Epoch 92 | Test Loss : 0.000163 | Time : 0.2686
Epoch 93 | Loss : 0.008031 | Time : 58.3960
Epoch 93 | Test Loss : 0.000164 | Time : 0.2797
Epoch 94 | Loss : 0.008042 | Time : 59.9102
Epoch 94 | Test Loss : 0.000165 | Time : 0.3069
Epoch 95 | Loss : 0.008019 | Time : 59.1631
Epoch 95 | Test Loss : 0.000165 | Time : 0.3056
Epoch 96 | Loss : 0.008074 | Time : 59.2769
Epoch 96 | Test Loss : 0.000165 | Time : 0.3014
Epoch 97 | Loss : 0.008034 | Time : 58.6269
Epoch 97 | Test Loss : 0.000164 | Time : 0.3064
Epoch 98 | Loss : 0.008018 | Time : 61.0191
Epoch 98 | Test Loss : 0.000165 | Time : 0.3125
Epoch 99 | Loss : 0.007994 | Time : 60.6650
Epoch 99 | Test Loss : 0.000166 | Time : 0.2817
Epoch 100 | Loss : 0.008002 | Time : 60.7396
Epoch 100 | Test Loss : 0.000164 | Time : 0.3081
===Final Evaluation===
Best Epoch 67 | MSE : 0.312887 | MAE : 14.828393 | PSNR : 39.709166 | SSIM : 0.985138
